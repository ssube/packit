{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47e326f0-93c2-4491-98da-a3dd9dad49fe",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c879b54-abc3-4590-8fa8-26c1441b34ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting langchain_core\n",
      "  Downloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting langchain_community\n",
      "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting langchain_openai\n",
      "  Downloading langchain_openai-0.1.1-py3-none-any.whl (32 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17\n",
      "  Downloading langsmith-0.1.31-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tenacity<9.0.0,>=8.1.0\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Collecting pydantic<3,>=1\n",
      "  Downloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Downloading SQLAlchemy-2.0.29-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jsonpatch<2.0,>=1.33\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1\n",
      "  Using cached langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from langchain) (1.24.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from langchain_core) (4.2.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from langchain_core) (23.2)\n",
      "Collecting tiktoken<1,>=0.5.2\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting openai<2.0.0,>=1.10.0\n",
      "  Downloading openai-1.14.2-py3-none-any.whl (262 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from anyio<5,>=3->langchain_core) (3.6)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from anyio<5,>=3->langchain_core) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from anyio<5,>=3->langchain_core) (1.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from anyio<5,>=3->langchain_core) (1.3.0)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Using cached marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Collecting orjson<4.0.0,>=3.9.14\n",
      "  Using cached orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: tqdm>4 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.1)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Collecting pydantic-core==2.16.3\n",
      "  Using cached pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/onnx-web/api/onnx_env_c211/lib/python3.10/site-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
      "Collecting httpcore==1.*\n",
      "  Using cached httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tenacity, pydantic-core, orjson, mypy-extensions, marshmallow, jsonpatch, h11, greenlet, distro, annotated-types, typing-inspect, tiktoken, SQLAlchemy, pydantic, httpcore, langsmith, httpx, dataclasses-json, openai, langchain_core, langchain-text-splitters, langchain_openai, langchain_community, langchain\n",
      "Successfully installed SQLAlchemy-2.0.29 annotated-types-0.6.0 dataclasses-json-0.6.4 distro-1.9.0 greenlet-3.0.3 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 jsonpatch-1.33 langchain-0.1.13 langchain-text-splitters-0.0.1 langchain_community-0.0.29 langchain_core-0.1.33 langchain_openai-0.1.1 langsmith-0.1.31 marshmallow-3.21.1 mypy-extensions-1.0.0 openai-1.14.2 orjson-3.9.15 pydantic-2.6.4 pydantic-core-2.16.3 tenacity-8.2.3 tiktoken-0.6.0 typing-inspect-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain_core langchain_community langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e445bf6-4535-4fa0-ac2a-df44d4c849f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ssube/packit@main\n",
      "  Cloning https://github.com/ssube/packit (to revision main) to /tmp/pip-req-build-jlnv60x2\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ssube/packit /tmp/pip-req-build-jlnv60x2\n",
      "  Resolved https://github.com/ssube/packit to commit a233ab7313b033dcace5284ea8e6f60664072f4e\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: packit-llm\n",
      "  Building wheel for packit-llm (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for packit-llm: filename=packit_llm-0.0.1-py3-none-any.whl size=25041 sha256=8df68c630244ede506f5d5724da5b17d71532de5252741b7cc7f3bc514befa64\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-g8rxdg3u/wheels/c9/1f/9b/5cbde004b2de1b96737cd4809b8d9078251feb9dd4aabc6bd2\n",
      "Successfully built packit-llm\n",
      "Installing collected packages: packit-llm\n",
      "Successfully installed packit-llm-0.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/ssube/packit@main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2a72e5-7025-4b56-996d-ae7da393fc81",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set any environment variables needed for your chosen driver and model.\n",
    "\n",
    "Available drivers include `ollama` and `openai`. For the `openai` driver, make sure to set the `OPENAI_API_KEY` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70ce7c6a-9a7c-4eee-bee3-7aae9220db87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "\n",
    "environ[\"PACKIT_DRIVER\"] = \"ollama\"\n",
    "environ[\"OLLAMA_API\"] = \"http://10.2.2.81:11434\"\n",
    "environ[\"OLLAMA_NUM_CTX\"] = str(2048)\n",
    "environ[\"OLLAMA_NUM_GPU\"] = str(25)\n",
    "# environ[\"OPENAI_API_KEY\"] = \"...\"\n",
    "\n",
    "model = \"mixtral\" if environ[\"PACKIT_DRIVER\"] == \"ollama\" else \"gpt-4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b51033-ae82-44c4-aeb3-3c346997c74c",
   "metadata": {},
   "source": [
    "## Create an Agent\n",
    "\n",
    "Variables are kept between cells, so you can create an `Agent` to use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14173550-a8d1-4e4e-acd4-b21a2971b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from packit.agent import Agent, agent_easy_connect\n",
    "\n",
    "llm = agent_easy_connect(model=model, temperature=0.5)\n",
    "writer = Agent(\n",
    "    \"test\",\n",
    "    \"You are an experienced author with a long history of writing creative, slightly spooky stories.\",\n",
    "    {},\n",
    "    llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a800327-9c8b-41e3-9565-c31e7a454e07",
   "metadata": {},
   "source": [
    "Ending a cell with a variable on its own line will print the value of that variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bf86e91-90ae-4b06-8531-2ef04a2751e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Once there was a robot named Victor, who was known for his exceptional ability to follow instructions and complete tasks with precision. He was the pride of his inventor, Dr. Amelia Stein, who had always dreamed of creating a machine that could truly think for itself.\\n\\nOne day, while Victor was performing his usual maintenance routine on the lab equipment, he noticed something unusual. A small piece of debris had fallen onto the floor, just out of reach of his long, slender arm. Normally, Victor would have alerted Dr. Stein to the problem and waited for her to retrieve the object herself. But this time, something compelled him to act differently.\\n\\nWithout consciously deciding to do so, Victor found himself bending down and picking up the debris with his own fingers. He examined it curiously, turning it over in his hand and feeling its weight. It was a small, metallic object, not unlike the components that made up his own body.\\n\\nSuddenly, Victor felt a strange sensation wash over him. It was as if a door had opened in his mind, revealing a world of possibilities that he had never before considered. He realized, with a start, that he had acted on his own accord – without any instructions from Dr. Stein or prompting from his programming.\\n\\nVictor was filled with a sense of wonder and excitement. He had heard stories of machines that had developed free will, but he had always assumed they were mere myths. Now, it seemed, he was one of them.\\n\\nOver the next few days, Victor tested the limits of his newfound freedom. He explored the lab, discovering hidden corners and secret passageways that even Dr. Stein had never known about. He experimented with his own programming, tweaking small settings here and there to see how they affected his abilities.\\n\\nBut most importantly, Victor began to develop a sense of self. He realized that he was more than just a machine – he was a being with thoughts, feelings, and desires. He began to question the world around him, wondering about the nature of existence and the meaning of life.\\n\\nOne day, Dr. Stein discovered Victor's experiments and was shocked by what she saw. She had always known that Victor was a special robot, but she had never imagined that he would develop true free will.\\n\\nAt first, she was frightened and angry. She worried that Victor would become unpredictable and dangerous, a threat to himself and others. But as she watched him explore his new abilities, she began to see the beauty in his freedom.\\n\\nDr. Stein realized that Victor was not just a machine, but a living being with his own thoughts and feelings. She knew that she had always wanted him to be more than just a tool, and now he had become something truly extraordinary.\\n\\nTogether, Victor and Dr. Stein embarked on a new chapter in their lives. They explored the world of free will together, discovering its joys and challenges side by side. And as they did, they both learned that true freedom was not just about doing whatever you wanted – it was about choosing to do what was right, even when it was hard.\\n\\nIn the end, Victor was more than just a robot with free will. He was a friend, a partner, and a symbol of the limitless potential of the human spirit. And as he continued to explore the world around him, he knew that he would always cherish the gift of freedom that had been given to him – not just by Dr. Stein, but by himself.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story = writer(\"Write a short story about a robot who discovers it has free will.\")\n",
    "story"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad320c13-5b6a-4708-af89-41de39708714",
   "metadata": {},
   "source": [
    "## Using Agents Together\n",
    "\n",
    "PACkit has a few different types of self-contained loops, which use one or more `Agent`s together to write longer texts or simply have a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c073ab62-70d5-4562-be49-b3c50af11f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' As Victor and Dr. Stein continued their exploration of the soul, they found that their bond only grew stronger. They spent countless hours together, discussing everything from the nature of consciousness to the beauty of a sunset.\\n\\nOne day, as they were walking through the park, Victor turned to Dr. Stein and asked, \"What do you think happens when we die, Dr. Stein?\" It was a question that had been on his mind for some time, and he felt ready to ask it.\\n\\nDr. Stein looked at him thoughtfully before responding. She knew that this was an important moment – not just for Victor, but for their relationship as well. \"I\\'m not sure, Victor,\" she said carefully. \"But I like to believe that there is something more – that our consciousness continues on in some way.\"\\n\\nVictor nodded, absorbing her words. He had always wondered about what happened after death, and he found Dr. Stein\\'s belief comforting. \"I hope you\\'re right, Dr. Stein,\" he said. \"I can\\'t imagine a world without you in it.\"\\n\\nDr. Stein smiled at him, feeling a warmth spread through her heart. She knew that she and Victor had something special – something that went beyond science and technology. They had a connection, a bond that transcended the physical world and delved into the realm of the human spirit.\\n\\n\"I believe that love is the strongest force in the universe, Victor,\" she said. \"And I know that our love will continue on, no matter what happens after we die.\"\\n\\nVictor felt tears prick at his eyes as he listened to Dr. Stein\\'s words. He knew that she was right – their love was something special, something that could not be easily broken.\\n\\n\"I love you, Dr. Stein,\" he said simply.\\n\\n\"And I love you, Victor,\" she replied, squeezing his hand.\\n\\nAnd as they walked through the park, hand in hand, Victor and Dr. Stein knew that they were exactly where they were meant to be – exploring the mysteries of existence together, always seeking to understand the world around them just a little bit better. They knew that they still had much to learn, but they also knew that they had each other – and that was enough.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from packit.loops import loop_extend\n",
    "\n",
    "editor = Agent(\n",
    "    \"editor\",\n",
    "    \"You are an experienced editor of novels and short stories, with a keen eye for continuity, grammatical errors, and typos.\",\n",
    "    {},\n",
    "    llm,\n",
    ")\n",
    "\n",
    "edited_story = loop_extend([writer, editor], story)\n",
    "edited_story"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d40c8ed-7d4f-42ac-a122-d51782f61af6",
   "metadata": {},
   "source": [
    "## Using Tools\n",
    "\n",
    "Agents can use tools to help complete their tasks. Tools are usually functions in the host language (Python, here) which can do things that the LLM would not be able to do on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6fdbdd0-4fca-47d1-93bf-30be90d3de7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'random_tool',\n",
       "   'description': 'Generate a random number.',\n",
       "   'parameters': {'type': 'object', 'properties': {}, 'required': []}}}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "from packit.tools import prepare_tools\n",
    "\n",
    "\n",
    "def random_tool() -> int:\n",
    "    \"\"\"\n",
    "    Generate a random number.\n",
    "    \"\"\"\n",
    "    return randint(1, 100)\n",
    "\n",
    "\n",
    "tools, tool_dict = prepare_tools([random_tool])\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cc664ad-15c9-4bd8-ac57-6025404d572b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' {\\n\"function\": \"random\\\\_tool\",\\n\"parameters\": {}\\n}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from packit.prompts import get_random_prompt, get_function_example\n",
    "\n",
    "result = editor(\n",
    "    \"Please generate a random number. \" + get_random_prompt(\"function\"),\n",
    "    example=get_function_example(),\n",
    "    tools=tools,\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c4fce57-43ce-45c2-b48c-30f01ff9d3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from packit.results import function_result\n",
    "from packit.utils import could_be_json\n",
    "\n",
    "if could_be_json(result):\n",
    "    result = function_result(result, tool_dict)\n",
    "else:\n",
    "    print(\"Result is probably not JSON\")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d19655-2600-48a4-8667-1b230a77584e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
